{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y_Th1_9kCR5Y"
      },
      "outputs": [],
      "source": [
        "#QUESTION1\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "zPGxzytnCV37"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing\n",
        "def read_tsv(path):\n",
        "    data = []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            target, source, freq = line.strip().split('\\t')\n",
        "            data.extend([(source, target)] * int(freq))\n",
        "    return data\n",
        "\n",
        "def build_vocab(data):\n",
        "    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "    for word in data:\n",
        "        for char in word:\n",
        "            if char not in vocab:\n",
        "                vocab[char] = len(vocab)\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "Bmvh0WUkCXIB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and Collate\n",
        "class TransliterationDataset(Dataset):\n",
        "    def __init__(self, pairs, src_vocab, tgt_vocab):\n",
        "        self.pairs = pairs\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_word, tgt_word = self.pairs[idx]\n",
        "        src_ids = [self.src_vocab[c] for c in src_word]\n",
        "        tgt_ids = [self.tgt_vocab['<sos>']] + [self.tgt_vocab[c] for c in tgt_word] + [self.tgt_vocab['<eos>']]\n",
        "        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_seqs, tgt_seqs = zip(*batch)\n",
        "    src_padded = nn.utils.rnn.pad_sequence(src_seqs, batch_first=True, padding_value=0)\n",
        "    tgt_padded = nn.utils.rnn.pad_sequence(tgt_seqs, batch_first=True, padding_value=0)\n",
        "    return src_padded, tgt_padded"
      ],
      "metadata": {
        "id": "jsr2kmT2CYtY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder and Decoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        _, hidden = self.rnn(embedded)\n",
        "        return hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.unsqueeze(1)  # (batch_size, 1)\n",
        "        embedded = self.embedding(input)\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        return self.fc_out(output.squeeze(1)), hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size, trg_len = trg.size()\n",
        "        vocab_size = self.decoder.fc_out.out_features\n",
        "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n",
        "\n",
        "        hidden = self.encoder(src)\n",
        "        input = trg[:, 0]  # <sos>\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden = self.decoder(input, hidden)\n",
        "            outputs[:, t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input = trg[:, t] if teacher_force else output.argmax(1)\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "CLEmaOL6CaBQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilities\n",
        "def predict(model, word, src_vocab, tgt_vocab, max_len=30):\n",
        "    model.eval()\n",
        "    rev_tgt_vocab = {i: c for c, i in tgt_vocab.items()}\n",
        "    src_tensor = torch.tensor([src_vocab[c] for c in word], dtype=torch.long).unsqueeze(0).to(model.device)\n",
        "    hidden = model.encoder(src_tensor)\n",
        "    input = torch.tensor([tgt_vocab['<sos>']], dtype=torch.long).to(model.device)\n",
        "    output = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        out, hidden = model.decoder(input, hidden)\n",
        "        top1 = out.argmax(1).item()\n",
        "        if rev_tgt_vocab[top1] == '<eos>':\n",
        "            break\n",
        "        output.append(rev_tgt_vocab[top1])\n",
        "        input = torch.tensor([top1], dtype=torch.long).to(model.device)\n",
        "\n",
        "    return ''.join(output)\n",
        "\n",
        "def evaluate_accuracy(model, loader, tgt_vocab):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for src, trg in loader:\n",
        "            src, trg = src.to(model.device), trg.to(model.device)\n",
        "            outputs = model(src, trg, 0)  # no teacher forcing\n",
        "            preds = outputs.argmax(2)\n",
        "            for p, t in zip(preds, trg):\n",
        "                if torch.equal(p[1:], t[1:]):  # ignoring <sos>\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "gwd59tC5Cblv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "def train(model, loader, optimizer, criterion, clip=1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, trg in loader:\n",
        "        src, trg = src.to(model.device), trg.to(model.device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        output = output[:, 1:].reshape(-1, output.size(-1))\n",
        "        trg = trg[:, 1:].reshape(-1)\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# Putting it All Together\n",
        "dev_path = \"/content/data1.tsv\"  # Make sure this path is correct\n",
        "data_pairs = read_tsv(dev_path)\n",
        "\n",
        "src_vocab = build_vocab([p[0] for p in data_pairs])\n",
        "tgt_vocab = build_vocab([p[1] for p in data_pairs])\n",
        "\n",
        "dataset = TransliterationDataset(data_pairs, src_vocab, tgt_vocab)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ENC = Encoder(len(src_vocab), emb_dim=64, hidden_dim=128, n_layers=1)\n",
        "DEC = Decoder(len(tgt_vocab), emb_dim=64, hidden_dim=128, n_layers=1)\n",
        "model = Seq2Seq(ENC, DEC, DEVICE).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "# -----------------------------\n",
        "# Optional: Train the model\n",
        "# -----------------------------\n",
        "# for epoch in range(10):\n",
        "#     loss = train(model, loader, optimizer, criterion)\n",
        "#     acc = evaluate_accuracy(model, loader, tgt_vocab)\n",
        "#     print(f\"Epoch {epoch+1}: Loss = {loss:.4f}, Accuracy = {acc:.4f}\")\n",
        "\n",
        "# Sample Predictions\n",
        "for i in range(5):\n",
        "    src, tgt = data_pairs[i]\n",
        "    pred = predict(model, src, src_vocab, tgt_vocab)\n",
        "    print(f\"Input: {src} | Target: {tgt} | Predicted: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRlES_bJCdxQ",
        "outputId": "4df631da-93a4-47e5-da45-0a71d23b6126"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: an | Target: अं | Predicted: झऐणऔर्खण्ए<pad>ततरथथह<pad>तरथहहइऔाथथहह\n",
            "Input: an | Target: अं | Predicted: झऐणऔर्खण्ए<pad>ततरथथह<pad>तरथहहइऔाथथहह\n",
            "Input: an | Target: अं | Predicted: झऐणऔर्खण्ए<pad>ततरथथह<pad>तरथहहइऔाथथहह\n",
            "Input: ankganit | Target: अंकगणित | Predicted: झऐणऔर्खण्ए<pad>ततरथथह<pad>तरथहहइऔाथथहह\n",
            "Input: ankganit | Target: अंकगणित | Predicted: झऐणऔर्खण्ए<pad>ततरथथह<pad>तरथहहइऔाथथहह\n"
          ]
        }
      ]
    }
  ]
}